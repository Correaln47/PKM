In real deployment scenarios, the processing unit inside the robot is limited compared to where the simulations are run. To put in perspective, a very accessible consumer graphics like the RTX 4070 super (550USD) is about 4.5 times faster than the Jetson AGX Thor (3500USD) in processing power. For specialized simulation scenarios, this difference scales far higher (like with specialized hardware in servers). That's why its important, specially in high risk or sensible robotics, to test the logic and data processing in the real hardware it would run on. This stage, as well as SIL, leverages powerful simulations to recreate the robot in its environment. However, with special interfaces, the “thought process” of the robot runs in the exact hardware it would be deployed in. This helps to see how fast and precise the response can really be. This is crucial because if a control system takes just a little more time than it did in the ideal case, it could change the whole result of the interaction. HIL is not always used, specially if the control systems are not as heavy computational wise, or if the system is not that critical/sensible. Also, to connect those generated signals from and to the simulation some specialized interfaces are needed, which can be expensive or hard to get, as they need to be very reliable and fast.
![[HILDiagram.drawio.png]]

